"""
Exemple d'utilisation Langchain avec le syst√®me RAG
==================================================

Cet exemple montre comment utiliser Langchain selon la documentation officielle :
- Embeddings Mistral et OpenAI
- VectorStore Supabase
- RAG chains avec reranking
- Document processing
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# Ajouter le r√©pertoire src au path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from rag.langchain.embeddings_integration import (
    LangchainEmbeddingProvider,
    LangchainVectorStore,
    LangchainRAGChain,
    LangchainDocumentProcessor,
    LangchainRAGWithReranking
)
from langchain_core.documents import Document
from rag.utils.config import config


def basic_langchain_example():
    """Exemple basique avec Langchain"""
    
    print("üöÄ Exemple Langchain basique...")
    
    # 1. Initialiser le fournisseur d'embeddings Mistral
    mistral_embedding = LangchainEmbeddingProvider(
        provider="mistral",
        model="mistral-embed"
    )
    
    print("‚úÖ Fournisseur Mistral initialis√©")
    
    # 2. Tester l'embedding
    test_text = "L'intelligence artificielle transforme notre monde"
    embedding = mistral_embedding.embed_query(test_text)
    print(f"üìä Embedding g√©n√©r√©: {len(embedding)} dimensions")
    
    # 3. Initialiser le VectorStore
    vector_store = LangchainVectorStore(
        embedding_provider=mistral_embedding
    )
    
    print("‚úÖ VectorStore Supabase initialis√©")
    
    # 4. Cr√©er des documents
    documents = [
        Document(
            page_content="L'IA est une technologie r√©volutionnaire qui permet aux machines d'apprendre.",
            metadata={"source": "article_1", "category": "technology"}
        ),
        Document(
            page_content="Le machine learning utilise des algorithmes pour analyser des donn√©es.",
            metadata={"source": "article_2", "category": "technology"}
        ),
        Document(
            page_content="Les r√©seaux de neurones sont inspir√©s du cerveau humain.",
            metadata={"source": "article_3", "category": "science"}
        )
    ]
    
    # 5. Ajouter les documents au VectorStore
    try:
        doc_ids = vector_store.add_documents(documents)
        print(f"‚úÖ {len(doc_ids)} documents ajout√©s au VectorStore")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de l'ajout des documents: {str(e)}")
        print("üí° Assurez-vous que Supabase est configur√© correctement")
    
    # 6. Recherche de similarit√©
    try:
        results = vector_store.similarity_search(
            "Qu'est-ce que l'intelligence artificielle ?",
            k=2
        )
        print(f"üîç {len(results)} documents trouv√©s")
        for i, doc in enumerate(results):
            print(f"  Document {i+1}: {doc.page_content[:50]}...")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de la recherche: {str(e)}")


def advanced_rag_chain_example():
    """Exemple avanc√© avec cha√Æne RAG compl√®te"""
    
    print("\nüîó Exemple cha√Æne RAG avanc√©e...")
    
    # 1. Initialiser la cha√Æne RAG
    rag_chain = LangchainRAGChain(
        embedding_provider="mistral",
        llm_provider="mistral",
        use_vector_store=True
    )
    
    print("‚úÖ Cha√Æne RAG initialis√©e")
    
    # 2. Cr√©er des documents avec le processeur
    processor = LangchainDocumentProcessor("mistral")
    
    texts = [
        "L'intelligence artificielle est une technologie qui permet aux machines d'apprendre et de prendre des d√©cisions de mani√®re autonome.",
        "Le machine learning est une sous-discipline de l'IA qui se concentre sur l'apprentissage automatique √† partir de donn√©es.",
        "Les r√©seaux de neurones artificiels sont inspir√©s du fonctionnement du cerveau humain et permettent de r√©soudre des probl√®mes complexes."
    ]
    
    metadatas = [
        {"title": "Introduction IA", "category": "technology"},
        {"title": "Machine Learning", "category": "technology"},
        {"title": "R√©seaux de neurones", "category": "science"}
    ]
    
    documents = processor.process_documents(texts, metadatas)
    print(f"üìÑ {len(documents)} documents trait√©s")
    
    # 3. Ajouter les documents √† la cha√Æne
    try:
        doc_ids = rag_chain.add_documents(documents)
        print(f"‚úÖ {len(doc_ids)} documents ajout√©s √† la cha√Æne")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de l'ajout: {str(e)}")
    
    # 4. Tester la cha√Æne RAG
    queries = [
        "Qu'est-ce que l'intelligence artificielle ?",
        "Comment fonctionne le machine learning ?",
        "Expliquez les r√©seaux de neurones"
    ]
    
    for query in queries:
        print(f"\n‚ùì Requ√™te: {query}")
        try:
            result = rag_chain.query(query)
            print(f"üí¨ R√©ponse: {result['answer']}")
            print(f"üìö Sources: {len(result['source_documents'])} documents")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de la requ√™te: {str(e)}")


def reranking_example():
    """Exemple avec reranking Cohere"""
    
    print("\nüîÑ Exemple avec reranking...")
    
    # 1. Initialiser la cha√Æne RAG
    rag_chain = LangchainRAGChain(
        embedding_provider="mistral",
        llm_provider="mistral"
    )
    
    # 2. Initialiser le RAG avec reranking
    rag_with_reranking = LangchainRAGWithReranking(rag_chain)
    
    print("‚úÖ RAG avec reranking initialis√©")
    
    # 3. Tester avec reranking
    query = "Quels sont les avantages de l'intelligence artificielle ?"
    print(f"\n‚ùì Requ√™te: {query}")
    
    try:
        result = rag_with_reranking.query_with_reranking(query)
        print(f"üí¨ R√©ponse: {result['answer']}")
        print(f"üîÑ Reranking: {result['reranked']}")
        print(f"üìö Documents rerank√©s: {len(result['source_documents'])}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors du reranking: {str(e)}")


def multi_provider_example():
    """Exemple avec plusieurs fournisseurs"""
    
    print("\nüîÑ Exemple multi-fournisseurs...")
    
    # Test avec diff√©rents fournisseurs d'embeddings
    providers = ["mistral", "openai"]
    
    for provider in providers:
        print(f"\nüîß Test avec {provider}...")
        
        try:
            # Initialiser le fournisseur
            embedding_provider = LangchainEmbeddingProvider(provider)
            
            # Tester l'embedding
            test_text = "Test d'embedding avec " + provider
            embedding = embedding_provider.embed_query(test_text)
            print(f"‚úÖ {provider}: {len(embedding)} dimensions")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur avec {provider}: {str(e)}")


def document_processing_example():
    """Exemple de traitement de documents"""
    
    print("\nüìÑ Exemple de traitement de documents...")
    
    # 1. Initialiser le processeur
    processor = LangchainDocumentProcessor("mistral")
    
    # 2. Documents de test
    texts = [
        "L'intelligence artificielle r√©volutionne la m√©decine en permettant un diagnostic plus pr√©cis.",
        "Les voitures autonomes utilisent l'IA pour naviguer de mani√®re s√©curis√©e.",
        "L'IA g√©n√©rative peut cr√©er du contenu artistique et litt√©raire de qualit√©."
    ]
    
    metadatas = [
        {"category": "m√©decine", "language": "fr"},
        {"category": "transport", "language": "fr"},
        {"category": "cr√©ativit√©", "language": "fr"}
    ]
    
    # 3. Traiter les documents
    documents = processor.process_documents(texts, metadatas)
    print(f"üìÑ {len(documents)} documents trait√©s")
    
    # 4. Ajouter les embeddings
    try:
        documents_with_embeddings = processor.embed_documents(documents)
        print(f"‚úÖ Embeddings ajout√©s aux documents")
        
        # Afficher les m√©tadonn√©es
        for i, doc in enumerate(documents_with_embeddings):
            print(f"  Document {i+1}: {doc.metadata['category']} - {len(doc.metadata.get('embedding', []))} dimensions")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de l'embedding: {str(e)}")


def main():
    """Fonction principale"""
    
    print("üéØ Syst√®me RAG avec Langchain - Exemples complets")
    print("=" * 60)
    
    try:
        # Exemples de base
        basic_langchain_example()
        
        # Exemples avanc√©s
        advanced_rag_chain_example()
        
        # Exemples avec reranking
        reranking_example()
        
        # Exemples multi-fournisseurs
        multi_provider_example()
        
        # Exemples de traitement de documents
        document_processing_example()
        
        print("\nüéâ Tous les exemples Langchain termin√©s avec succ√®s !")
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors de l'ex√©cution: {str(e)}")
        print("üí° V√©rifiez votre configuration et vos cl√©s API")


if __name__ == "__main__":
    main()
