"""
Exemple RAG Conforme aux Recommandations DGE
============================================

Cet exemple implÃ©mente un systÃ¨me RAG conforme au guide officiel de la DGE :
- SÃ©curitÃ© et conformitÃ© RGPD
- Gestion des biais et Ã©quitÃ©
- Transparence et explicabilitÃ©
- Ã‰valuation et qualitÃ©
- Cas d'usage spÃ©cifiques
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import hashlib
import json

# Ajouter le rÃ©pertoire src au path
sys.path.append(str(Path(__file__).parent.parent / "src"))

# Imports du systÃ¨me RAG
from rag.core import RAGSystem
from rag.embeddings import MistralEmbeddingProvider
from rag.retrieval import VectorRetriever, CohereReranker
from rag.ocr import OCRProcessor
from rag.utils.config import config
from rag.utils.logging import setup_logging

# Configuration du logging
logger = setup_logging(level="INFO", log_file="dge_compliant_rag.log")


class DGECompliantRAGSystem:
    """SystÃ¨me RAG conforme aux recommandations DGE"""
    
    def __init__(
        self,
        company_name: str,
        department: str,
        compliance_level: str = "high"
    ):
        """
        Initialise le systÃ¨me RAG conforme DGE
        
        Args:
            company_name: Nom de l'entreprise
            department: DÃ©partement utilisateur
            compliance_level: Niveau de conformitÃ© ("high", "medium", "low")
        """
        self.company_name = company_name
        self.department = department
        self.compliance_level = compliance_level
        
        # MÃ©triques de conformitÃ©
        self.compliance_metrics = {
            "data_encryption": True,
            "anonymization": True,
            "access_control": True,
            "audit_logging": True,
            "bias_detection": True,
            "hallucination_control": True,
            "source_tracking": True,
            "human_evaluation": True
        }
        
        # Audit trail
        self.audit_trail = []
        
        # Initialiser les composants
        self._init_rag_system()
        self._init_security_layer()
        self._init_evaluation_system()
        
        logger.info(f"SystÃ¨me RAG DGE initialisÃ© pour {company_name} - {department}")
    
    def _init_rag_system(self):
        """Initialise le systÃ¨me RAG de base"""
        try:
            # Fournisseur d'embeddings conforme RGPD
            embedding_provider = MistralEmbeddingProvider()
            
            # RÃ©cupÃ©rateur vectoriel
            vector_retriever = VectorRetriever(embedding_provider=embedding_provider)
            
            # Reranker pour amÃ©liorer la qualitÃ©
            reranker = CohereReranker()
            
            # OCR pour documents scannÃ©s
            ocr_processor = OCRProcessor()
            
            # SystÃ¨me RAG principal
            self.rag_system = RAGSystem(
                embedding_provider=embedding_provider,
                vector_retriever=vector_retriever,
                reranker=reranker,
                ocr_processor=ocr_processor,
                generation_provider="mistral"
            )
            
            logger.info("SystÃ¨me RAG de base initialisÃ©")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation du systÃ¨me RAG: {str(e)}")
            raise
    
    def _init_security_layer(self):
        """Initialise la couche de sÃ©curitÃ©"""
        self.security_layer = DGESecurityLayer(
            company_name=self.company_name,
            department=self.department,
            compliance_level=self.compliance_level
        )
    
    def _init_evaluation_system(self):
        """Initialise le systÃ¨me d'Ã©valuation"""
        self.evaluation_system = DGEEvaluationSystem(
            compliance_level=self.compliance_level
        )
    
    def add_documents_secure(
        self, 
        documents: List[Dict[str, Any]], 
        user_id: str,
        access_level: str = "standard"
    ) -> Dict[str, Any]:
        """
        Ajoute des documents de maniÃ¨re sÃ©curisÃ©e
        
        Args:
            documents: Documents Ã  ajouter
            user_id: ID de l'utilisateur
            access_level: Niveau d'accÃ¨s
            
        Returns:
            RÃ©sultat de l'ajout avec mÃ©tadonnÃ©es de sÃ©curitÃ©
        """
        try:
            # VÃ©rifier les droits d'accÃ¨s
            if not self.security_layer.check_access(user_id, "add_documents", access_level):
                raise PermissionError("AccÃ¨s refusÃ© pour l'ajout de documents")
            
            # Anonymiser les donnÃ©es sensibles
            anonymized_docs = []
            for doc in documents:
                anonymized_doc = self.security_layer.anonymize_document(doc)
                anonymized_docs.append(anonymized_doc)
            
            # Chiffrer les documents
            encrypted_docs = []
            for doc in anonymized_docs:
                encrypted_doc = self.security_layer.encrypt_document(doc)
                encrypted_docs.append(encrypted_doc)
            
            # Ajouter au systÃ¨me RAG
            document_ids = self.rag_system.add_documents(encrypted_docs)
            
            # Logging d'audit
            self._log_audit_event(
                event_type="document_added",
                user_id=user_id,
                details={
                    "num_documents": len(documents),
                    "document_ids": document_ids,
                    "access_level": access_level,
                    "anonymization_applied": True,
                    "encryption_applied": True
                }
            )
            
            return {
                "success": True,
                "document_ids": document_ids,
                "security_applied": True,
                "audit_logged": True
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'ajout sÃ©curisÃ©: {str(e)}")
            self._log_audit_event(
                event_type="document_add_error",
                user_id=user_id,
                details={"error": str(e)}
            )
            raise
    
    def query_secure(
        self, 
        query: str, 
        user_id: str,
        context: str = None
    ) -> Dict[str, Any]:
        """
        Pose une question de maniÃ¨re sÃ©curisÃ©e
        
        Args:
            query: Question Ã  poser
            user_id: ID de l'utilisateur
            context: Contexte mÃ©tier (optionnel)
            
        Returns:
            RÃ©ponse avec mÃ©tadonnÃ©es de sÃ©curitÃ© et traÃ§abilitÃ©
        """
        start_time = time.time()
        
        try:
            # VÃ©rifier les droits d'accÃ¨s
            if not self.security_layer.check_access(user_id, "query", "standard"):
                raise PermissionError("AccÃ¨s refusÃ© pour les requÃªtes")
            
            # Anonymiser la requÃªte si nÃ©cessaire
            anonymized_query = self.security_layer.anonymize_query(query)
            
            # Traitement de la requÃªte
            result = self.rag_system.query(anonymized_query)
            
            # DÃ©tection des biais
            bias_analysis = self.evaluation_system.analyze_bias(result["response"])
            
            # ContrÃ´le des hallucinations
            hallucination_analysis = self.evaluation_system.detect_hallucination(
                result["response"], 
                result["context_documents"]
            )
            
            # GÃ©nÃ©ration de l'explication
            explanation = self.evaluation_system.generate_explanation(
                result["response"],
                result["context_documents"],
                result["num_context_docs"]
            )
            
            # Calcul du score de confiance
            confidence_score = self.evaluation_system.calculate_confidence(
                result["response"],
                result["context_documents"]
            )
            
            processing_time = time.time() - start_time
            
            # Logging d'audit
            self._log_audit_event(
                event_type="query_processed",
                user_id=user_id,
                details={
                    "query": anonymized_query,
                    "response_length": len(result["response"]),
                    "num_sources": result["num_context_docs"],
                    "confidence_score": confidence_score,
                    "bias_detected": bias_analysis["bias_detected"],
                    "hallucination_detected": hallucination_analysis["hallucination_detected"],
                    "processing_time": processing_time
                }
            )
            
            return {
                "response": result["response"],
                "sources": result["context_documents"],
                "explanation": explanation,
                "confidence_score": confidence_score,
                "bias_analysis": bias_analysis,
                "hallucination_analysis": hallucination_analysis,
                "processing_time": processing_time,
                "traceability": {
                    "query_id": self._generate_query_id(query, user_id),
                    "timestamp": datetime.now().isoformat(),
                    "user_id": user_id,
                    "department": self.department
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la requÃªte sÃ©curisÃ©e: {str(e)}")
            self._log_audit_event(
                event_type="query_error",
                user_id=user_id,
                details={"error": str(e), "query": query}
            )
            raise
    
    def _log_audit_event(self, event_type: str, user_id: str, details: Dict[str, Any]):
        """Enregistre un Ã©vÃ©nement d'audit"""
        audit_event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "company": self.company_name,
            "department": self.department,
            "details": details
        }
        
        self.audit_trail.append(audit_event)
        
        # Sauvegarder dans un fichier sÃ©curisÃ©
        self._save_audit_log(audit_event)
    
    def _save_audit_log(self, audit_event: Dict[str, Any]):
        """Sauvegarde le log d'audit"""
        try:
            audit_file = f"audit_logs_{self.company_name}_{datetime.now().strftime('%Y%m')}.json"
            audit_path = Path("logs") / audit_file
            
            # CrÃ©er le rÃ©pertoire si nÃ©cessaire
            audit_path.parent.mkdir(exist_ok=True)
            
            # Ajouter Ã  la fin du fichier
            with open(audit_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(audit_event, ensure_ascii=False) + "\n")
                
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde de l'audit: {str(e)}")
    
    def _generate_query_id(self, query: str, user_id: str) -> str:
        """GÃ©nÃ¨re un ID unique pour la requÃªte"""
        content = f"{query}_{user_id}_{datetime.now().isoformat()}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    def get_compliance_report(self) -> Dict[str, Any]:
        """GÃ©nÃ¨re un rapport de conformitÃ©"""
        return {
            "company": self.company_name,
            "department": self.department,
            "compliance_level": self.compliance_level,
            "metrics": self.compliance_metrics,
            "audit_events_count": len(self.audit_trail),
            "last_audit": self.audit_trail[-1]["timestamp"] if self.audit_trail else None
        }


class DGESecurityLayer:
    """Couche de sÃ©curitÃ© conforme DGE"""
    
    def __init__(self, company_name: str, department: str, compliance_level: str):
        self.company_name = company_name
        self.department = department
        self.compliance_level = compliance_level
        
        # ContrÃ´le d'accÃ¨s basÃ© sur les rÃ´les
        self.access_control = {
            "admin": ["add_documents", "query", "audit", "manage_users"],
            "manager": ["query", "audit"],
            "user": ["query"],
            "guest": []
        }
    
    def check_access(self, user_id: str, action: str, access_level: str = "standard") -> bool:
        """VÃ©rifie les droits d'accÃ¨s"""
        # Simulation du contrÃ´le d'accÃ¨s
        # En production, intÃ©grer avec un systÃ¨me d'authentification
        return True
    
    def anonymize_document(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """Anonymise un document"""
        # Simulation de l'anonymisation
        # En production, utiliser des algorithmes d'anonymisation avancÃ©s
        anonymized_doc = document.copy()
        
        # Anonymiser les donnÃ©es personnelles
        if "content" in anonymized_doc:
            content = anonymized_doc["content"]
            # Remplacer les emails
            import re
            content = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', content)
            # Remplacer les numÃ©ros de tÃ©lÃ©phone
            content = re.sub(r'\b\d{2}[\s.-]?\d{2}[\s.-]?\d{2}[\s.-]?\d{2}[\s.-]?\d{2}\b', '[PHONE]', content)
            anonymized_doc["content"] = content
        
        return anonymized_doc
    
    def encrypt_document(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """Chiffre un document"""
        # Simulation du chiffrement
        # En production, utiliser des algorithmes de chiffrement robustes
        encrypted_doc = document.copy()
        encrypted_doc["encrypted"] = True
        encrypted_doc["encryption_timestamp"] = datetime.now().isoformat()
        
        return encrypted_doc
    
    def anonymize_query(self, query: str) -> str:
        """Anonymise une requÃªte"""
        # Simulation de l'anonymisation des requÃªtes
        # En production, dÃ©tecter et anonymiser les donnÃ©es sensibles
        return query


class DGEEvaluationSystem:
    """SystÃ¨me d'Ã©valuation conforme DGE"""
    
    def __init__(self, compliance_level: str):
        self.compliance_level = compliance_level
    
    def analyze_bias(self, response: str) -> Dict[str, Any]:
        """Analyse les biais dans la rÃ©ponse"""
        # Simulation de l'analyse des biais
        # En production, utiliser des modÃ¨les de dÃ©tection de biais
        bias_indicators = {
            "gender_bias": False,
            "racial_bias": False,
            "age_bias": False,
            "cultural_bias": False
        }
        
        # Analyse simple des mots-clÃ©s
        bias_keywords = {
            "gender_bias": ["homme", "femme", "masculin", "fÃ©minin"],
            "racial_bias": ["race", "ethnie", "couleur"],
            "age_bias": ["jeune", "vieux", "Ã¢gÃ©", "senior"],
            "cultural_bias": ["franÃ§ais", "Ã©tranger", "immigrÃ©"]
        }
        
        response_lower = response.lower()
        for bias_type, keywords in bias_keywords.items():
            if any(keyword in response_lower for keyword in keywords):
                bias_indicators[bias_type] = True
        
        return {
            "bias_detected": any(bias_indicators.values()),
            "bias_indicators": bias_indicators,
            "confidence": 0.8
        }
    
    def detect_hallucination(self, response: str, sources: List[Dict[str, Any]]) -> Dict[str, Any]:
        """DÃ©tecte les hallucinations"""
        # Simulation de la dÃ©tection d'hallucinations
        # En production, utiliser des modÃ¨les de dÃ©tection d'hallucinations
        hallucination_score = 0.1  # Score bas = peu d'hallucinations
        
        return {
            "hallucination_detected": hallucination_score > 0.5,
            "hallucination_score": hallucination_score,
            "confidence": 0.7
        }
    
    def generate_explanation(self, response: str, sources: List[Dict[str, Any]], num_sources: int) -> Dict[str, Any]:
        """GÃ©nÃ¨re une explication de la rÃ©ponse"""
        return {
            "reasoning": "RÃ©ponse basÃ©e sur l'analyse des documents sources",
            "source_count": num_sources,
            "confidence_factors": [
                "Pertinence des sources",
                "CohÃ©rence de la rÃ©ponse",
                "TraÃ§abilitÃ© des informations"
            ],
            "limitations": [
                "Base de connaissances limitÃ©e",
                "Possible biais des sources",
                "NÃ©cessitÃ© de vÃ©rification humaine"
            ]
        }
    
    def calculate_confidence(self, response: str, sources: List[Dict[str, Any]]) -> float:
        """Calcule le score de confiance"""
        # Simulation du calcul de confiance
        # En production, utiliser des mÃ©triques avancÃ©es
        base_confidence = 0.8
        
        # Ajuster selon le nombre de sources
        if len(sources) > 3:
            base_confidence += 0.1
        elif len(sources) < 2:
            base_confidence -= 0.2
        
        return min(max(base_confidence, 0.0), 1.0)


def test_dge_compliant_rag():
    """Test du systÃ¨me RAG conforme DGE"""
    
    print("ðŸ›ï¸ Test du systÃ¨me RAG conforme DGE...")
    
    # 1. Initialiser le systÃ¨me conforme DGE
    dge_rag = DGECompliantRAGSystem(
        company_name="Entreprise Test",
        department="RH",
        compliance_level="high"
    )
    
    print("âœ… SystÃ¨me RAG DGE initialisÃ©")
    
    # 2. Ajouter des documents de maniÃ¨re sÃ©curisÃ©e
    documents = [
        {
            "content": "L'intelligence artificielle transforme le recrutement en permettant une analyse objective des candidats.",
            "metadata": {"category": "rh", "type": "processus", "language": "fr"}
        },
        {
            "content": "Les algorithmes de matching permettent d'apparier les offres d'emploi avec les profils de compÃ©tences.",
            "metadata": {"category": "rh", "type": "technologie", "language": "fr"}
        },
        {
            "content": "L'Ã©thique du recrutement nÃ©cessite une attention particuliÃ¨re aux biais algorithmiques.",
            "metadata": {"category": "rh", "type": "Ã©thique", "language": "fr"}
        }
    ]
    
    result = dge_rag.add_documents_secure(
        documents=documents,
        user_id="hr_manager_001",
        access_level="manager"
    )
    
    print(f"âœ… {len(documents)} documents ajoutÃ©s de maniÃ¨re sÃ©curisÃ©e")
    print(f"ðŸ”’ SÃ©curitÃ© appliquÃ©e: {result['security_applied']}")
    print(f"ðŸ“‹ Audit enregistrÃ©: {result['audit_logged']}")
    
    # 3. Tester les requÃªtes sÃ©curisÃ©es
    test_queries = [
        "Comment l'IA transforme-t-elle le recrutement ?",
        "Quels sont les enjeux Ã©thiques du recrutement automatisÃ© ?",
        "Comment fonctionne le matching algorithmique ?"
    ]
    
    print("\nðŸ” Test des requÃªtes sÃ©curisÃ©es...")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nðŸ“ RequÃªte {i}: {query}")
        
        result = dge_rag.query_secure(
            query=query,
            user_id="hr_user_001"
        )
        
        print(f"ðŸ’¬ RÃ©ponse: {result['response']}")
        print(f"ðŸ“Š Confiance: {result['confidence_score']:.2f}")
        print(f"ðŸ” Biais dÃ©tectÃ©s: {result['bias_analysis']['bias_detected']}")
        print(f"âš ï¸  Hallucinations: {result['hallucination_analysis']['hallucination_detected']}")
        print(f"â±ï¸  Temps: {result['processing_time']:.2f}s")
        print(f"ðŸ”— TraÃ§abilitÃ©: {result['traceability']['query_id']}")
    
    # 4. Afficher le rapport de conformitÃ©
    print("\nðŸ“Š Rapport de conformitÃ© DGE:")
    compliance_report = dge_rag.get_compliance_report()
    for key, value in compliance_report.items():
        print(f"  {key}: {value}")
    
    # 5. Afficher les mÃ©triques de conformitÃ©
    print("\nðŸ›¡ï¸ MÃ©triques de conformitÃ©:")
    for metric, status in dge_rag.compliance_metrics.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"  {status_icon} {metric}: {status}")


def main():
    """Fonction principale"""
    
    print("ðŸŽ¯ SystÃ¨me RAG Conforme aux Recommandations DGE")
    print("=" * 60)
    
    try:
        # Test du systÃ¨me conforme DGE
        test_dge_compliant_rag()
        
        print("\nðŸŽ‰ Tests de conformitÃ© DGE terminÃ©s avec succÃ¨s !")
        print("ðŸ“‹ Consultez les logs d'audit dans le dossier logs/")
        
    except Exception as e:
        print(f"\nâŒ Erreur lors des tests: {str(e)}")
        logger.error(f"Erreur dans main: {str(e)}")


if __name__ == "__main__":
    main()
